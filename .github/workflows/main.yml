# üîπ ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á Workflow
name: MLOps Pipeline CI/CT/CD

# üîπ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£ push ‡∏´‡∏£‡∏∑‡∏≠ pull request ‡πÑ‡∏õ‡∏¢‡∏±‡∏á branch 'main'
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  # -------------------- üîπ JOB 1: CI Checks --------------------
  ci-checks:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r mlops_pipeline/requirements.txt
          pip install flake8 pytest pandas

      - name: Lint with flake8
        run: |
          flake8 mlops_pipeline/scripts --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 mlops_pipeline/scripts --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Test with pytest
        run: |
          pytest || (if [ $? -eq 5 ]; then echo "Pytest finished: No tests found."; exit 0; else exit $?; fi)

  # -------------------- üîπ JOB 2: Build & Train --------------------
  build-and-train:
    needs: ci-checks
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_TRACKING_USERNAME }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_TRACKING_PASSWORD }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r mlops_pipeline/requirements.txt
          pip install kaggle

      # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å Kaggle ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô
      - name: Download Dataset from Kaggle
        env:
          KAGGLE_JSON: ${{ secrets.KAGGLE_JSON }}
        run: |
          echo "$KAGGLE_JSON" > kaggle.json
          mkdir -p ~/.kaggle
          mv kaggle.json ~/.kaggle/
          chmod 600 ~/.kaggle/kaggle.json

          echo "üì• Downloading Kaggle dataset..."
          mkdir -p mlops_pipeline/data
          kaggle datasets download -d ammaralfaifi/5class-weather-status-image-classification -p mlops_pipeline/data --unzip
          echo "‚úÖ Dataset downloaded successfully."

      - name: Fix dataset folder structure
        run: |
          echo "üîß Checking folder structure..."
          if [ -d "mlops_pipeline/data/data" ]; then
            echo "‚öôÔ∏è Moving dataset up one level..."
            mv mlops_pipeline/data/data/* mlops_pipeline/data/
            rm -rf mlops_pipeline/data/data
          fi
          echo "‚úÖ Dataset structure fixed."
          ls mlops_pipeline/data

      - name: Check and remove corrupted images
        run: |
          python -m pip install tensorflow pillow
          python mlops_pipeline/scripts/find_corrupted.py

      # ‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô pipeline ‡∏õ‡∏Å‡∏ï‡∏¥
      - name: Run Data Validation
        run: python mlops_pipeline/scripts/01_data_validation.py

      - name: Run Data Preprocessing
        id: preprocessing
        run: python mlops_pipeline/scripts/02_preprocessing.py

      - name: Run Model Training, Evaluation, and Registration
        run: python mlops_pipeline/scripts/03_train_model.py

      - name: Run Model Full Evaluation
        run: python mlops_pipeline/scripts/04_evaluate_model.py
  
      - name: Test API prediction (smoke test)
        run: |
          pip install fastapi uvicorn python-multipart pillow
          # üí° ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° . (Current Directory) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô PYTHONPATH
          # ‡πÉ‡∏ô GitHub Actions (Linux) ‡πÉ‡∏ä‡πâ export
          export PYTHONPATH=$PYTHONPATH:. 
          
          echo "üöÄ Starting API for Smoke Test..."
          python -m uvicorn mlops_pipeline.deployment.app:app --host 0.0.0.0 --port 8000 &
          sleep 10
          
          echo "Checking API Health..."
          curl -X 'GET' 'http://127.0.0.1:8000/' | grep "Weather Classifier API"
          echo "‚úÖ API Smoke Test completed."

      - name: Transition Model to Staging
        if: success()
        # üö® ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Argument: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 'Staging' ‡πÄ‡∏õ‡πá‡∏ô 'Latest' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        run: python mlops_pipeline/scripts/04_evaluate_model.py "weather-classifier-prod" "Latest"

      - name: Upload MLflow artifacts for inspection
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-artifacts
          path: mlruns/

      
