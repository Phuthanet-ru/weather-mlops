import os
import tensorflow as tf
import mlflow
# üí° ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ MLflow ‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏• Artifacts ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠
mlflow.set_tracking_uri("file:./mlruns")


def preprocess_data(data_dir="data", img_size=(128, 128), batch_size=32):
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° train/test split
    """
    mlflow.set_experiment("Weather Classification - Data Preprocessing")

    with mlflow.start_run() as run:
        run_id = run.info.run_id
        mlflow.set_tag("ml.step", "data_preprocessing")

        print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° preprocessing (Run ID: {run_id})")

        # ‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
        train_ds = tf.keras.preprocessing.image_dataset_from_directory(
            data_dir,
            validation_split=0.2,
            subset="training",
            seed=42,
            image_size=img_size,
            batch_size=batch_size
        )
        val_ds = tf.keras.preprocessing.image_dataset_from_directory(
            data_dir,
            validation_split=0.2,
            subset="validation",
            seed=42,
            image_size=img_size,
            batch_size=batch_size
        )

        mlflow.log_param("img_size", img_size)
        mlflow.log_param("batch_size", batch_size)
        mlflow.log_metric("train_batches", len(train_ds))
        mlflow.log_metric("val_batches", len(val_ds))

        print("‚úÖ Data preprocessing ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")

        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö workflow ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏ô GitHub Actions
        if "GITHUB_OUTPUT" in os.environ:
            with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å run_id ‡πÄ‡∏õ‡πá‡∏ô output ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Job ‡∏ï‡πà‡∏≠‡πÑ‡∏õ
                print(f"run_id={run_id}", file=f)

if __name__ == "__main__":
    preprocess_data("mlops_pipeline/data")